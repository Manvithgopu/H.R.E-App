â¤ï¸ Heart Rate Estimation App
Non-invasive Heart Rate Monitoring using Smartphone Camera, Computer Vision & Machine Learning


ğŸ“Œ Overview
The Heart Rate Estimation App is an Android application that estimates a user's heart rate using only the smartphone camera. The app processes video frames, analyzes facial color variations, and sends extracted data to a server-based ML model to predict heart rate with improved accuracy.
Built using Kotlin + Jetpack Compose, the app integrates modern Android technologies including:

CameraX â€“ High-quality, device-compatible video recording
Google ML Kit â€“ Face detection & contour segmentation
Firebase Authentication & Storage â€“ Secure login + cloud video storage
Ngrok Tunnel â€“ Secure communication with server
Server ML Model (IIT Indore) â€“ Processes RGB time-series to estimate heart rate


â­ Features
ğŸ”’ Secure Login & Signup using Firebase Auth
ğŸ¥ CameraX video recorder with smart bounding box
ğŸ™‚ Real-time face detection â€“ starts recording only when face is perfectly aligned
ğŸ—‚ï¸ Cloud-based Gallery â€“ fetch recorded videos from Firebase
ğŸ“Š Frame-by-Frame Image Processing
ğŸŒˆ RGB extraction of facial regions
ğŸ”— Server-side ML inference for accurate heart rate prediction
ğŸ“± Modern Jetpack Compose UI


ğŸ—ï¸ Architecture
1. User Interface Layer (Jetpack Compose)

Login / Register
Home Screen
Camera Screen (with live bounding box)
Gallery Screen
Video Player & Analysis Screen

2. Authentication & Storage Layer
Firebase Authentication
Firebase Cloud Storage for user video 

3. Video Capture Layer
CameraX API
ML Kit face detection before & during recording

4. Image Analysis Layer
Face isolation (masking background)
Contour detection
Face region divided into grid boxes
RGB extraction (green channel emphasized)
Time-series creation from per-frame RGB data

5. Server & ML Prediction Layer
Processed RGB array â†’ sent via HTTP POST
Server hosted ML model (IIT Indore)
Ngrok for secure URL endpoint
Returns predicted heart rate


ğŸ§  How It Works (Pipeline)
User logs in
Records video with face properly aligned
Frames â†’ Face isolated â†’ Contour extracted
Grid segmentation â†’ RGB values computed
Time-series sent to ML server
Model predicts heart rate
Result displayed in app


ğŸš€ Installation (Developer Setup)
Prerequisites

Android Studio Flamingo or newer
Firebase project
Ngrok account (for server tunneling)
ML model hosted on server


Steps
Clone the repository
git clone https://github.com/your-username/your-repo.git

Open in Android Studio
Add your google-services.json in /app
Configure Firebase Authentication & Storage
Set your server/ngrok URL in the networking file
Run app on a real Android device (recommended)


ğŸ“ˆ Performance
âœ”ï¸ Higher accuracy vs traditional video-based apps
âœ”ï¸ Robust face detection reduces background noise
âœ”ï¸ Server-side ML handles lighting variations better
âœ”ï¸ Works across wide range of Android devices


âš ï¸ Limitations
Dependent on stable internet (server processing)
Sensitive to lighting changes
Requires still head position during recording
Lower performance on low-end devices for HD videos


ğŸ”® Future Improvements
On-device ML to remove internet dependency
Multi-parameter health monitoring (SpO2, respiration, stress)
Automatic lighting normalization
Integration with wearables and fitness platforms
AI-based motion stabilization



ğŸ“„ License
This project is for academic & research use. Add a license if required.












